{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Linear Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of supervised learning\n",
    "\n",
    "- **Classification:** Predict a categorical response\n",
    "- **Regression:** Predict a continuous response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:** fast, no tuning required, highly interpretable, well-understood\n",
    "\n",
    "**Cons:** unlikely to produce the best predictive accuracy (presumes a linear relationship between the features and response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Use the **pandas library** to read data into Python.\n",
    "- Use the **display library** to visualize data.\n",
    "- Understand **linear regression**, and how does it work.\n",
    "- Understand **train and interpret** a linear regression model in scikit-learn.\n",
    "- Learn some **evaluation metrics** for regression problems.\n",
    "- How do I choose **which features to include** in my model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We'll be using [Statsmodels](http://statsmodels.sourceforge.net/) for **teaching purposes** since it has some nice characteristics for linear modeling. However, we recommend that you spend most of your energy on [scikit-learn](http://scikit-learn.org/stable/) since it provides significantly more useful functionality for machine learning in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets, linear_model\n",
    "from IPython.display import display\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn import metrics\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# allow plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Advertising Data\n",
    "\n",
    "Let's take a look at some data, ask some questions about that data, and then use linear regression to answer those questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>225</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.672</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.797</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>190</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.761</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.2</td>\n",
       "      <td>180</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.651</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.9</td>\n",
       "      <td>205</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.900</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2     X3     X4     Y\n",
       "1  6.8  225  0.442  0.672   9.2\n",
       "2  6.3  180  0.435  0.797  11.7\n",
       "3  6.4  190  0.456  0.761  15.8\n",
       "4  6.2  180  0.416  0.651   8.6\n",
       "5  6.9  205  0.449  0.900  23.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read CSV file stored in the current directory and save the results\n",
    "data = pd.read_csv('basketball.csv', skipinitialspace=True, index_col=0)\n",
    "\n",
    "# display the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the features?\n",
    "- **TV:** advertising dollars spent on TV for a single product in a given market (in thousands of dollars)\n",
    "- **Radio:** advertising dollars spent on Radio\n",
    "- **Newspaper:** advertising dollars spent on Newspaper\n",
    "\n",
    "What is the response?\n",
    "- **Sales:** sales of a single product in a given market (in thousands of items)\n",
    "\n",
    "What else do we know?\n",
    "- Because the response variable is continuous, this is a **regression** problem.\n",
    "- There are 200 **observations** (represented by the rows), and each observation is a single market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-496aa2a93ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#display all data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'display' is not defined"
     ]
    }
   ],
   "source": [
    "#display all data\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary object types:\n",
    "\n",
    "- **DataFrame:** rows and columns (like a spreadsheet)\n",
    "- **Series:** a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.8</td>\n",
       "      <td>180</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.872</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7.4</td>\n",
       "      <td>240</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.713</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.8</td>\n",
       "      <td>225</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.701</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6.8</td>\n",
       "      <td>215</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.734</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>7.0</td>\n",
       "      <td>230</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.764</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1   X2     X3     X4     Y\n",
       "50  5.8  180  0.425  0.872  11.8\n",
       "51  7.4  240  0.599  0.713  17.1\n",
       "52  6.8  225  0.482  0.701  11.6\n",
       "53  6.8  215  0.457  0.734   5.8\n",
       "54  7.0  230  0.435  0.764   8.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the last 5 rows\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the DataFrame (rows, columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualizing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions About the Advertising Data\n",
    "\n",
    "Let's pretend you work for the company that manufactures and markets this widget. The company might ask you the following: On the basis of this data, how should we spend our advertising money in the future?\n",
    "\n",
    "This general question might lead you to more specific questions:\n",
    "1. Is there a relationship between ads and sales?\n",
    "2. How strong is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. What is the effect of each ad type of sales?\n",
    "5. Given ad spending in a particular market, can sales be predicted?\n",
    "\n",
    "We will explore these questions below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a **quantitative response** using a **single feature** (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What does each term represent?\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to predict Sales!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "Generally speaking, coefficients are estimated using the **least squares criterion**, which means we are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate the model coefficients for the advertising data (only using the variables TV and Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Estimating Model using 'X1' and 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    17.625617\n",
       "X1           -0.885812\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS (method1) ###\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "# create a fitted model\n",
    "lm1 = smf.ols(formula='Y ~ X1', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dd2f673219c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m# instantiate and fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;31m# Create linear regression object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;31m# Train the model using the training sets (this time we use all data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN (method2) ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['X1']\n",
    "X = data[feature_cols]\n",
    "y = data['Y']   \n",
    "\n",
    "# instantiate and fit\n",
    "# Create linear regression object\n",
    "lm2 = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets (this time we use all data)\n",
    "lm2.fit(X, y)\n",
    "\n",
    "# print intercept\n",
    "print ('Intercept: ', lm2.intercept_)\n",
    "          \n",
    "# print the coefficients     \n",
    "print('Coefficients: ', lm2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Model Coefficients\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.047537 \"unit\" increase in Sales.\n",
    "- Or more clearly: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.537 widgets.\n",
    "\n",
    "Note that if an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data and the regression function\n",
    "\n",
    "Plot scatterplot and the regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model for Prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.032594 + 0.047537 \\times 50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.409444"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually calculate the prediction\n",
    "7.032594 + 0.047537*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e5d1e20b514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;31m# you have to create a DataFrame since the Statsmodels formula interface expects it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'X1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m# predict for a new observation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# you have to create a DataFrame since the Statsmodels formula interface expects it\n",
    "X_new = pd.DataFrame({'X1': [50]})\n",
    "\n",
    "# predict for a new observation\n",
    "lm1.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-26.66498034])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# predict for a new observation\n",
    "lm2.predict(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0b6ef4e1e5d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Plot scatterplot and the regression function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'observed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot scatterplot and the regression function\n",
    "plt.scatter(X, y, color='black', label='observed')\n",
    "\n",
    "plt.xlim([5.5,7.8])\n",
    "plt.ylim([0, 30])\n",
    "plt.plot(X, lm2.predict(X), label='fit', color='blue', linewidth=2)\n",
    "\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we would predict Sales of 9,409 widgets in that market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Estimating Model using 'X2' and 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe3dd7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### SCIKIT-LEARN (method2) ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['X2']\n",
    "X = data[feature_cols]\n",
    "y = data['Y']   \n",
    "\n",
    "# instantiate and fit\n",
    "lm2 = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets (this time we use all data)\n",
    "lm2.fit(X, y)\n",
    "\n",
    "# Plot scatterplot and the regression function\n",
    "plt.scatter(X, y, color='black', label='observed')\n",
    "\n",
    "plt.xlim([90, 275])\n",
    "plt.ylim([0, 30])\n",
    "plt.plot(X, lm2.predict(X), label='fit', color='Cyan', linewidth=2)\n",
    "\n",
    "plt.xlabel('X2')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Model using 'Newspaper' and 'Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe4bca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### SCIKIT-LEARN (method2) ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['X4']\n",
    "X = data[feature_cols]\n",
    "y = data['Y']   \n",
    "\n",
    "# instantiate and fit\n",
    "lm2 = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets (this time we use all data)\n",
    "lm2.fit(X, y)\n",
    "\n",
    "# Plot scatterplot and the regression function\n",
    "plt.scatter(X, y, color='black', label='observed')\n",
    "\n",
    "plt.xlim([0.2,0.95])\n",
    "plt.ylim([0, 30])\n",
    "plt.plot(X, lm2.predict(X), label='fit', color='Green', linewidth=2)\n",
    "\n",
    "plt.xlabel('X4')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Well Does the Model Fit the data?\n",
    "\n",
    "The most common way to evaluate the overall fit of a linear model is by the **R-squared** value. R-squared is the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the **null model**. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "\n",
    "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. Here's an example of what R-squared \"looks like\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the R-squared value for our simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0047480226587224283"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print the R-squared value for the model\n",
    "lm1.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 32.1090\n",
      "Variance score: 0.0600\n"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.4f\" % np.mean((lm2.predict(X) - y) ** 2))\n",
    "\n",
    "# print the R-squared value (explained variance score) for the model: 1 is perfect prediction\n",
    "print('Variance score: %.4f' % lm2.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that a \"good\" R-squared value? It's hard to say. The threshold for a good R-squared value depends widely on the domain. Therefore, it's most useful as a tool for **comparing different models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple linear regression can easily be extended to include multiple features. This is called **multiple linear regression**:\n",
    "### Form of linear regression\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature)\n",
    "\n",
    "In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$\n",
    "\n",
    "The $\\beta$ values are called the **model coefficients**. These values are \"learned\" during the model fitting step using the \"least squares\" criterion. Then, the fitted model can be used to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate these coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     4.148707\n",
       "X1           -3.690499\n",
       "X2            0.009458\n",
       "X3           47.940199\n",
       "X4           11.371019\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# create a fitted model with all three features\n",
    "lm1 = smf.ols(formula='Y~X1 + X2 + X3 + X4', data=data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Intercept: ', array([ 4.14870671]))\n",
      "('Coefficients: ', array([[ -3.69049908e+00,   9.45845788e-03,   4.79401992e+01,\n",
      "          1.13710193e+01]]))\n"
     ]
    }
   ],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['X1', 'X2', 'X3','X4']\n",
    "X = data[feature_cols]\n",
    "y = data[['Y']]\n",
    "\n",
    "# instantiate and fit\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print ('Intercept: ', lm2.intercept_)\n",
    "print ('Coefficients: ', lm2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Jun 2017</td> <th>  Prob (F-statistic):</th>  <td>0.0136</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:15:24</td>     <th>  Log-Likelihood:    </th> <td> -165.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    54</td>      <th>  AIC:               </th> <td>   340.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    49</td>      <th>  BIC:               </th> <td>   350.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    4.1487</td> <td>   14.855</td> <td>    0.279</td> <td> 0.781</td> <td>  -25.704    34.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>   -3.6905</td> <td>    2.971</td> <td>   -1.242</td> <td> 0.220</td> <td>   -9.661     2.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.0095</td> <td>    0.046</td> <td>    0.204</td> <td> 0.839</td> <td>   -0.084     0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>   47.9402</td> <td>   15.709</td> <td>    3.052</td> <td> 0.004</td> <td>   16.372    79.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>   11.3710</td> <td>    7.869</td> <td>    1.445</td> <td> 0.155</td> <td>   -4.441    27.183</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.089</td> <th>  Durbin-Watson:     </th> <td>   2.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.029</td> <th>  Jarque-Bera (JB):  </th> <td>   6.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.835</td> <th>  Prob(JB):          </th> <td>  0.0393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.296</td> <th>  Cond. No.          </th> <td>4.60e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.222\n",
       "Model:                            OLS   Adj. R-squared:                  0.159\n",
       "Method:                 Least Squares   F-statistic:                     3.501\n",
       "Date:                Sun, 11 Jun 2017   Prob (F-statistic):             0.0136\n",
       "Time:                        20:15:24   Log-Likelihood:                -165.17\n",
       "No. Observations:                  54   AIC:                             340.3\n",
       "Df Residuals:                      49   BIC:                             350.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      4.1487     14.855      0.279      0.781       -25.704    34.001\n",
       "X1            -3.6905      2.971     -1.242      0.220        -9.661     2.280\n",
       "X2             0.0095      0.046      0.204      0.839        -0.084     0.102\n",
       "X3            47.9402     15.709      3.052      0.004        16.372    79.509\n",
       "X4            11.3710      7.869      1.445      0.155        -4.441    27.183\n",
       "==============================================================================\n",
       "Omnibus:                        7.089   Durbin-Watson:                   2.099\n",
       "Prob(Omnibus):                  0.029   Jarque-Bera (JB):                6.471\n",
       "Skew:                           0.835   Prob(JB):                       0.0393\n",
       "Kurtosis:                       3.296   Cond. No.                     4.60e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.6e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print a summary of the fitted model\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Discussion\n",
    "\n",
    "How do I decide **which features to include** in a linear model? Here's one idea:\n",
    "- Try different models, and only keep features in the model if they have small p-values.\n",
    "- Check whether the R-squared value goes up when you add new features.\n",
    "\n",
    "What are the **drawbacks** to this approach?\n",
    "- Linear models rely upon a lot of **assumptions** (such as the features being independent), and if those assumptions are violated (which they usually are), R-squared and p-values are less reliable.\n",
    "- Using a p-value cutoff of 0.05 means that if you add 100 features to a model that are **pure noise**, 5 of them (on average) will still be counted as significant.\n",
    "- R-squared is susceptible to **overfitting**, and thus there is no guarantee that a model with a high R-squared value will generalize. Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89719426108289557"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# only include TV and Radio in the model\n",
    "lm1 = smf.ols(formula='Sales ~ TV + Radio', data=data).fit()\n",
    "lm1.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89721063817895219"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add Newspaper to the model (which we believe has no association with Sales)\n",
    "lm1 = smf.ols(formula='Sales ~ TV + Radio + Newspaper', data=data).fit()\n",
    "lm1.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared will always increase as you add more features to the model**, even if they are unrelated to the response. Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
    "\n",
    "There is alternative to R-squared called **adjusted R-squared** that penalizes model complexity (to control for overfitting), but it generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html).\n",
    "\n",
    "So is there a better approach to feature selection? **Train/test split** or **cross-validation.** They provide a more reliable estimate of out-of-sample error, and thus are better for choosing which of your models will best **generalize** to out-of-sample data. There is extensive functionality for cross-validation in scikit-learn, including automated methods for searching different sets of parameters and different models. Importantly, cross-validation can be applied to **any model**, whereas the methods described above only apply to **linear models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation metrics for regression\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. Instead, we need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate **three common evaluation metrics** for regression problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these metrics:\n",
    "\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple examples for evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "150.0\n",
      "150.0\n",
      "12.2474487139\n",
      "12.2474487139\n"
     ]
    }
   ],
   "source": [
    "# define true and predicted response values\n",
    "true = [100, 50, 30, 20]\n",
    "pred = [90, 50, 50, 30]\n",
    "\n",
    "# calculate MAE by hand\n",
    "print((10 + 0 + 20 + 10)/4.)\n",
    "\n",
    "# calculate MAE using scikit-learn\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(true, pred))\n",
    "\n",
    "\n",
    "# calculate MSE by hand\n",
    "print((10**2 + 0**2 + 20**2 + 10**2)/4.)\n",
    "\n",
    "# calculate MSE using scikit-learn\n",
    "print(metrics.mean_squared_error(true, pred))\n",
    "\n",
    "# calculate RMSE by hand\n",
    "import numpy as np\n",
    "print(np.sqrt((10**2 + 0**2 + 20**2 + 10**2)/4.))\n",
    "\n",
    "# calculate RMSE using scikit-learn\n",
    "print(np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our example of the regression for 'TV' and 'Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (54,4) and (1,) not aligned: 4 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-00efa5defdd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# make predictions on the testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlm2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# compute the RMSE of our predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sgs\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sgs\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 253\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\sgs\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (54,4) and (1,) not aligned: 4 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "y_pred = lm2.predict(X)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## *** Multiple Linear Regression Analysis on Advertising Data ***\n",
    "## 1. Preparing X and Y using pandas\n",
    "\n",
    "- scikit-learn expects X (feature matrix) and Y (response vector) to be NumPy arrays.\n",
    "- However, pandas is built on top of NumPy.\n",
    "- Thus, X can be a pandas DataFrame and y can be a pandas Series!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>225</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>190</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.2</td>\n",
       "      <td>180</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.9</td>\n",
       "      <td>205</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2     X3     X4\n",
       "1  6.8  225  0.442  0.672\n",
       "2  6.3  180  0.435  0.797\n",
       "3  6.4  190  0.456  0.761\n",
       "4  6.2  180  0.416  0.651\n",
       "5  6.9  205  0.449  0.900"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['X1', 'X2', 'X3','X4']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = data[feature_cols]\n",
    "\n",
    "# equivalent command to do the above in one line\n",
    "X = data[['X1', 'X2', 'X3','X4']]\n",
    "\n",
    "# print the first 5 rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(54, 4)\n"
     ]
    }
   ],
   "source": [
    "# check the type and shape of X\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     9.2\n",
       "2    11.7\n",
       "3    15.8\n",
       "4     8.6\n",
       "5    23.2\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a Series from the DataFrame\n",
    "y = data['Y']\n",
    "\n",
    "# print the first 5 values\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "(54L,)\n"
     ]
    }
   ],
   "source": [
    "# check the type and shape of y\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4)\n",
      "(40L,)\n",
      "(14, 4)\n",
      "(14L,)\n"
     ]
    }
   ],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.57826772809\n",
      "[ -4.48739639e+00  -1.61106170e-03   5.45351082e+01   1.16369781e+01]\n"
     ]
    }
   ],
   "source": [
    "# print the intercept and coefficients\n",
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X1', -4.4873963910636521),\n",
       " ('X2', -0.0016110616959847321),\n",
       " ('X3', 54.535108179539357),\n",
       " ('X4', 11.63697806336272)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair the feature names with the coefficients\n",
    "list(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = 2.88 + 0.0466 \\times TV + 0.179 \\times Radio + 0.00345 \\times Newspaper$$\n",
    "\n",
    "How do we interpret the **TV coefficient** (0.0466)?\n",
    "\n",
    "- For a given amount of Radio and Newspaper ad spending, **a \"unit\" increase in TV ad spending** is associated with a **0.0466 \"unit\" increase in Sales**.\n",
    "- Or more clearly: For a given amount of Radio and Newspaper ad spending, **an additional $1,000 spent on TV ads** is associated with an **increase in sales of 46.6 items**.\n",
    "\n",
    "Important notes:\n",
    "\n",
    "- This is a statement of **association**, not **causation**.\n",
    "- If an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "from sklearn import metrics\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an **evaluation metric** in order to compare our predictions with the actual values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Computing the RMSE for our Sales predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.80097045037\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is lower than the RMSE value for the regression where we use only TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature selection consideration\n",
    "\n",
    "Does **Newspaper** \"belong\" in our model? In other words, does it improve the quality of our predictions?\n",
    "\n",
    "Let's **remove it** from the model and check the RMSE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.064799636\n"
     ]
    }
   ],
   "source": [
    "# create a Python list of feature names\n",
    "feature_cols = ['X4', 'X3','X2']\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select a Series from the DataFrame\n",
    "y = data.Y\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE **decreased** when we removed Newspaper from the model. (Error is something we want to minimize, so **a lower number for RMSE is better**.) Thus, it is unlikely that this feature is useful for predicting Sales, and should be removed from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Linear regression:\n",
    "- [Introduction to linear regression](http://people.duke.edu/~rnau/regintro.htm) by Robert Nau (Duke)\n",
    "\n",
    "Pandas:\n",
    "- [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) and [read_table](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html) documentation\n",
    "\n",
    "##### The parts of the code were implemented by Kevin Markham"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
